[package]
name = "privateai"
version = "0.1.0"
description = "CaribbeanTechS - Private AI Assistant"
authors = ["CaribbeanTechS"]
license = ""
repository = ""
edition = "2021"

[build-dependencies]
tauri-build = { version = "1.5", features = [] }

[dependencies]
tauri = { version = "1.5", features = [ "dialog-open", "fs-all", "path-all", "shell-open"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
tokio = { version = "1", features = ["full"] }
reqwest = { version = "0.11", features = ["json", "stream"] }
sysinfo = "0.30"
dirs = "5.0"
futures-util = "0.3"
tracing-subscriber = { version = "0.3", features = ["fmt", "env-filter"] }
tracing-appender = "0.2"

# Embedded runtime dependencies
llama-cpp-2 = { version = "0.1", optional = true }
anyhow = "1.0"

[features]
default = ["runtime-embedded"]
runtime-ollama = []
runtime-python = []
runtime-embedded = ["llama-cpp-2"]
custom-protocol = ["tauri/custom-protocol"]

[target.'cfg(target_os = "macos")'.dependencies]
cocoa = "0.25"
